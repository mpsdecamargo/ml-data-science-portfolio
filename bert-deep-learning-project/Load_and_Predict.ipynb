{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mpsdecamargo/ml-data-science-portfolio/blob/main/bert-deep-learning-project/Load_and_Predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## INTRODUCTION\n",
        "\n",
        "Notebook content: Loading of models and prediction of sample corpus. Sample of final function to save output into JSON format to be sent to the front end of the application and to the user."
      ],
      "metadata": {
        "id": "Irke-TsEjvhz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZHWW5TVuH3T",
        "outputId": "de9b3e23-457e-4e7c-ccd7-597c90e3784e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Collecting sentence_transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.16.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Collecting pyarrow-hotfix (from datasets)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (2.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
            "Building wheels for collected packages: sentence_transformers\n",
            "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=3fda6e7c9e1bf331d3ad78f0abc5a8302f98bf4dea4d946423e8223ef2a9733b\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence_transformers\n",
            "Installing collected packages: sentencepiece, pyarrow-hotfix, dill, multiprocess, datasets, sentence_transformers\n",
            "Successfully installed datasets-2.16.1 dill-0.3.7 multiprocess-0.70.15 pyarrow-hotfix-0.6 sentence_transformers-2.2.2 sentencepiece-0.1.99\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece transformers sentence_transformers datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZohAM_BBl3J",
        "outputId": "8f522d8b-4c5b-4fbe-be76-706816d1033c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hOYO4WzOuNoL"
      },
      "outputs": [],
      "source": [
        "import sentencepiece\n",
        "import pandas as pd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "import json\n",
        "import time\n",
        "import operator\n",
        "import re\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import pickle\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from scipy.special import expit\n",
        "import io\n",
        "from contextlib import redirect_stdout"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lang_models = {\"BERTPT\":\"neuralmind/bert-base-portuguese-cased\",\"BERTPTL\":\"neuralmind/bert-large-portuguese-cased\",\"MBERT\":\"bert-base-multilingual-cased\", \"ELECTRA\":\"dlb/electra-base-portuguese-uncased-brwac\",\"ROBERTA\": \"rdenadai/BR_BERTo\",\"XLMR\":\"xlm-roberta-base\",\"DISTILBERT\": \"distilbert-base-multilingual-cased\",\"ALBERT\":\"josu/albert-pt-br\",\"DEBERTA\":\"microsoft/mdeberta-v3-base\"}\n"
      ],
      "metadata": {
        "id": "zIghTxztU_vW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOmOBNt7cjnP",
        "outputId": "d1f18df7-cc8e-4543-e669-f5b70df1a5db"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining of the input data to be analysed\n",
        "# The first 5 samples are true (label = 0)\n",
        "# The last 5 are cases of disinformation (label = 1)\n",
        "\n",
        "prediction_corpus = [\n",
        "\n",
        "'Cientistas dizem haver \"evidências convincentes\" de que o mercado de frutos do mar e vida selvagem de Huanan, na cidade chinesa de Wuhan, foi o epicentro do surto de covid-19. Isso sugere que houve duas variantes introduzidas em humanos em novembro ou início de dezembro de 2019. Os pesquisadores dizem que há evidências de que o Sars-Cov-2 estava presente em mamíferos vivos que foram vendidos no mercado de Huanan no final de 2019. Cientistas dizem que o coronavírus foi transmitido para pessoas que estavam trabalhando ou fazendo compras lá em duas \"infecções por transbordamento\" separadas — em que um humano contraiu o vírus de um animal.',\n",
        "\n",
        "'No decorrer da pandemia de covid-19, descobrimos quem pode estar em maior risco de contrair o vírus e desenvolver os casos mais graves da doença. Idade avançada, obesidade e várias comorbidades, como diabetes e hipertensão, são alguns desses fatores de risco. O alto índice de massa corporal (IMC) também parece estar associado ao aumento das chances de contrair o vírus, em primeiro lugar. Mas e os fatores que podem tornar alguém menos propenso a contrair covid? Curiosamente, pesquisas apontam que ter alergias pode reduzir o risco. As alergias são muito comuns. Pelo menos 400 milhões de pessoas em todo o mundo são afetadas por alergias ao pólen, conhecida em inglês como hay fever. Cerca de 300 milhões de pessoas sofrem de asma alérgica (induzida pela inalação de alérgenos), enquanto as alergias alimentares afetam cerca de 250 milhões. Muitas pessoas também são alérgicas a certos medicamentos. As reações alérgicas podem variar de leves (talvez alguma vermelhidão e inchaço na pele) a graves (choque anafilático, que pode causar a morte)',\n",
        "\n",
        "'Eficácia da vacina contra Covid-19 em gestantes é confirmada; menos de 10% apresentaram reações adversas. A pesquisa avaliou dados de mais de 85 mil partos realizados no Canadá e nos EUA no ano de 2021.',\n",
        "\n",
        "'As subvariantes BA.4 e BA.5 do novo coronavírus conseguem escapar dos anticorpos de pessoas que tiveram infecção anterior por Covid-19 e aquelas que já receberam a dose de reforço da vacina, de acordo com novos dados de pesquisadores da Escola de Medicina de Harvard. No entanto, a vacinação contra a Covid-19 ainda fornece proteção substancial contra formas graves da doença, e os fabricantes de imunizantes estão trabalhando na atualização de vacinas contra as variantes. Os níveis de anticorpos neutralizantes que uma infecção anterior ou vacinação provocam são várias menores contra as subvariantes BA.4 e BA.5, da Ômicron, em comparação com a cepa original do novo coronavírus, de acordo com a nova pesquisa publicada no New England Journal of Medicine na quarta-feira (22).',\n",
        "\n",
        "'O presidente americano, Joe Biden, disse neste domingo (18) que a pandemia de Covid-19 acabou nos Estados Unidos. \"A pandemia terminou\", disse em entrevista à TV. \"Ainda temos um problema com a Covid. Ainda estamos trabalhando muito nisso... Mas a pandemia acabou. Se prestarem atenção, ninguém usa máscaras. Todo mundo parece estar em boa forma. E, por isso, acredito que está mudando\", afirmou durante o programa \"60 Minutes\", da rede CBS, durante a feira de automóveis de Detroit, evento que não acontecia havia três anos.',\n",
        "\n",
        "'EXPOSIÇÃO MICROSCÓPICA DAS VACINAS Em SP, um telão exibe o que um microscópio revela estar presente em uma única gota das vacinas Pfizer, AstraZeneca, Johnson e CoronaVac. Pode ser ver os nano dispositivos, sensores e muitas bactérias',\n",
        "\n",
        "'URGENTE-HARVARD COMPROVA EFICÁCIA DA HIDROXICLOROQUINA Em estudos randomizados, controlados por placebo, duplo cego, pessoas designadas para uso de hidroxicloroquina tiveram 28% menos risco de COvid 19, afirmou Dr, Miguel Herman, professor de Havard. E AGORA?',\n",
        "\n",
        "'Desde o lançamento das vacinas de mRNA COVID-19, muitos pesquisadores especularam sobre a possibilidade de transmissão de partículas vacinais do vacinado para o não vacinado, mais comumente conhecido como “derramamento de vacina”. Um recente estudo de pré-impressão atraiu a atenção da mídia, pois os resultados do estudo podem ser interpretados como sugestivos de transmissão da vacina por disseminação. Desde o lançamento das vacinas de mRNA COVID-19, muitos pesquisadores especularam sobre a possibilidade de transmissão de partículas vacinais do vacinado para o não vacinado, mais comumente conhecido como “derramamento de vacina”. Embora essas especulações sejam rotineiramente verificadas, histórias anedóticas de pessoas não vacinadas que foram infectadas com COVID-19 ou experimentaram sintomas estranhos após o contato com amigos ou familiares que foram vacinados persistiram. Vários médicos também especularam sobre uma possível transmissão à medida que surgem novas descobertas em apoio a essas ideias. Um recente estudo de pré-impressão atraiu a atenção da mídia, pois os resultados do estudo podem ser interpretados como sugestivos de transmissão da vacina por disseminação.',\n",
        "\n",
        "'Um novo estudo prospectivo que inclui mais de 223.000 participantes do sul do Brasil descobriu que a ivermectina reduz a mortalidade por covid-19 em 92% . O uso de ivermectina foi associado a reduções não apenas na mortalidade por COVID-19, mas também nas hospitalizações e nas taxas de infecção. Como profilático, a ivermectina mostrou-se mais eficaz de maneira dose-dependente. À medida que a dose de ivermectina aumentava, os pacientes tinham maior probabilidade de se recuperar da covid-19. Evidências preliminares também mostram que os pacientes se recuperam mais rapidamente com ivermectina .',\n",
        "\n",
        "'O câncer começa quando as alterações genéticas interferem na replicação normal e na reposição das células do corpo. As células começam a crescer descontroladamente e podem formar um tumor. É a segunda principal causa de morte nos Estados Unidos. Infelizmente, parece que a doença pode estar aumentando graças às injeções experimentais de Covid-19. Porque os dados oficiais do governo dos EUA confirmam que o risco de desenvolver câncer após a vacinação contra o Covid-19 aumenta em chocantes 143.233%'\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "tsFL6lUfgh8U"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the tokenizer and creation of tokenize function.\n",
        "# The tokenizer transforms the text data into tokens, which are essentially different numbers,\n",
        "# which are then used in training.\n",
        "\n",
        "def startTokenizer(model_type):\n",
        "  load = time.time()\n",
        "  tokenizer = AutoTokenizer.from_pretrained(lang_models[model_type])\n",
        "  end = time.time()\n",
        "  tokenizationLoad = end - load\n",
        "  print(\"Loading Tokenization: \", tokenizationLoad)\n",
        "  return tokenizer\n",
        "\n",
        "def tokenize(text, tokenizer):\n",
        "    tokenized_input = tokenizer(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        padding='max_length',\n",
        "        return_tensors='np',\n",
        "        return_attention_mask=True,\n",
        "        return_token_type_ids=True,\n",
        "    )\n",
        "    return {\n",
        "        'input_ids': tokenized_input['input_ids'][0],\n",
        "        'attention_mask': tokenized_input['attention_mask'][0],\n",
        "        'token_type_ids': tokenized_input['token_type_ids'][0],\n",
        "    }"
      ],
      "metadata": {
        "id": "oLr8JaA4eGn5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the repositories of the pretrained language models to be used\n",
        "\n",
        "model_paths = {\n",
        "               \"BERTPT\":\"gdrive/My Drive/Modelos/BERTPT/BERTPT_Model_2024-01-02_23-23\",\n",
        "               \"BERTPTL\":\"gdrive/My Drive/Modelos/BERTPTL/BERTPTL_Model_2024-01-03_16-05\",\n",
        "               \"MBERT\":\"gdrive/My Drive/Modelos/MBERT/MBERT_Model_2024-01-03_01-17\",\n",
        "               \"ELECTRA\":\"gdrive/My Drive/Modelos/ELECTRA/ELECTRA_Model_2024-01-02_22-21\",\n",
        "               \"ROBERTA\": \"gdrive/MyDrive/Modelos/ROBERTA/ROBERTA_Model_2024-01-06_21-14\",\n",
        "               \"XLMR\":\"gdrive/My Drive/Modelos/XLMR/XLMR_Model_2024-01-05_16-19\",\n",
        "               \"DISTILBERT\": \"gdrive/My Drive/Modelos/DISTILBERT/DISTILBERT_Model_2024-01-02_21-13\",\n",
        "               \"ALBERT\":\"gdrive/My Drive/Modelos/ALBERT/ALBERT_Model_2024-01-02_17-54\",\n",
        "               \"DEBERTA\":\"gdrive/My Drive/Modelos/DEBERTA/DEBERTA_Model_2024-01-03_10-24\",\n",
        "               \"BERTPT_ML\": \"gdrive/My Drive/Modelos/MultiLabel/BERTPT/BERTPT_MultiLabelModel_2024-01-03_20-24\",\n",
        "               \"DEBERTA_ML\": \"gdrive/My Drive/Modelos/MultiLabel/DEBERTA/DEBERTA_MultiLabelModel_2024-01-03_20-43\"\n",
        "               }"
      ],
      "metadata": {
        "id": "8VoaZYf4dFFO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function loaded_model_predict loads the tokenizer and the model, tokenizes the dataset,\n",
        "# sets configuration of the parameters of the Trainer and uses the loaded model to predict based on input data.\n",
        "# If the multilabel parameter is defined to true, the configuration is changed and, also, the function returns the prediction for each theme instead.\n",
        "\n",
        "def loaded_model_predict(model_type,dataset=prediction_corpus, multilabel=False):\n",
        "  start = time.time()\n",
        "  loaded_tokenizer = AutoTokenizer.from_pretrained(model_paths[model_type])\n",
        "  loaded_model = AutoModelForSequenceClassification.from_pretrained(model_paths[model_type])\n",
        "  if multilabel == True:\n",
        "    loaded_model.config.problem_type = \"multi_label_classification\"\n",
        "  tokenized_prediction_corpus = [tokenize(text, loaded_tokenizer) for text in dataset]\n",
        "  tokenized_dataset = Dataset.from_dict({\"input_ids\": [item['input_ids'] for item in tokenized_prediction_corpus],\n",
        "                                           \"attention_mask\": [item['attention_mask'] for item in tokenized_prediction_corpus],\n",
        "                                           \"token_type_ids\": [item['token_type_ids'] for item in tokenized_prediction_corpus]})\n",
        "  training_args = TrainingArguments(\n",
        "        output_dir=f\"./test_trainer/{model_type}\",\n",
        "        do_train = False,\n",
        "        do_predict = True,\n",
        "        )\n",
        "\n",
        "  trainer = Trainer(\n",
        "      model=loaded_model,\n",
        "      args=training_args,\n",
        "  )\n",
        "\n",
        "  results = trainer.predict(tokenized_dataset)\n",
        "  if multilabel:\n",
        "    predicted_labels = np.round(expit(np.array(results.predictions)))\n",
        "  else:\n",
        "    predicted_labels = np.argmax(results.predictions, axis=-1)\n",
        "  end = time.time()\n",
        "  pred_time = end - start\n",
        "  print(predicted_labels)\n",
        "  print(f\"Prediction Time: {pred_time}\")\n",
        "  return predicted_labels"
      ],
      "metadata": {
        "id": "2yKCkvByplZG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CORPUS PREDICTION"
      ],
      "metadata": {
        "id": "jCx1eQKzo_wV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_predict(\"BERTPT\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "9qbKmlcN_NfR",
        "outputId": "313feb9f-cfe8-4525-c4c0-adb298d4b731"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 1 0 0 1 1 1 1 1]\n",
            "Prediction Time: 10.95037293434143\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 0, 0, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_predict(\"ALBERT\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "arqMDQyjXHV4",
        "outputId": "3e85ade5-ce08-421f-f927-e2b50ec1a848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 1 0 0 1 1 0 1 1]\n",
            "Prediction Time: 2.3080694675445557\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 0, 0, 1, 1, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_predict(\"ELECTRA\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "EzJVpOxLXHkB",
        "outputId": "2e6e2b91-d8b3-41d0-a3ab-f3a303d1432a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 1 0 0 1 1 0 1 1]\n",
            "Prediction Time: 17.68340516090393\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 0, 0, 1, 1, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_predict(\"MBERT\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "gCs2qLnWXHoB",
        "outputId": "671bd992-7f67-474d-b36e-aba0d3e39a80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 1 0 0 1 1 1 1 1]\n",
            "Prediction Time: 13.806703567504883\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_predict(\"DISTILBERT\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "o-xuxH-vXIQS",
        "outputId": "756685bc-05f6-4fe7-c94b-acfff7b12e45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 1 0 0 1 1 0 1 1]\n",
            "Prediction Time: 17.033589601516724\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_predict(\"DEBERTA\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "WAviJyZHXIT6",
        "outputId": "8aab699d-989b-4ed8-f918-7f9c43bfc744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 1 0 0 1 1 1 1 1]\n",
            "Prediction Time: 25.240070819854736\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 0, 0, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_predict(\"ROBERTA\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "u9r_SFw2XIXY",
        "outputId": "f6f75474-0eb2-4781-b613-8139bb561203"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 0 0 1 1 0 1 1]\n",
            "Prediction Time: 19.10265350341797\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_predict(\"XLMR\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "7uZUf76JXIvI",
        "outputId": "3cf07cdf-f359-474b-b8d9-66d89d5e8fde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 1 0 0 1 1 1 1 1]\n",
            "Prediction Time: 32.86075973510742\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 0, 0, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_predict(\"BERTPTL\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "ySsrF_jcXI6f",
        "outputId": "0561f0c6-fcb5-4a90-9ea7-b31fb03b5137"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 1 0 0 1 1 0 0 1]\n",
            "Prediction Time: 40.95278239250183\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 0, 0, 1, 1, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MULTILABEL PREDICTION"
      ],
      "metadata": {
        "id": "XxpCi4VwDhWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_predict(\"BERTPT_ML\", multilabel=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "b7WZU21EEkhz",
        "outputId": "0940512f-a635-4c98-d9ad-482fe41fbf43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0.]]\n",
            "Prediction Time: 9.870826482772827\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_predict(\"DEBERTA_ML\", multilabel=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "Zfzd74DceJxG",
        "outputId": "7437deb4-0cca-4b72-9970-520b1ce705c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0.]]\n",
            "Prediction Time: 18.725408792495728\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SENTENCE SIMILARITY ASSESSMENT"
      ],
      "metadata": {
        "id": "1JlJV4plDEP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_top5(queries):\n",
        "  # Loads the Sentence-BERT model\n",
        "  embedder = SentenceTransformer('distiluse-base-multilingual-cased-v2')\n",
        "  # Loads the dataset containing information about the similar texts\n",
        "  df = pd.read_csv(\"/content/gdrive/MyDrive/Datasets/dataset_verifato_sentence_similarity.csv\", sep=\";\")\n",
        "  # Transforms the claimReviewed column into a list\n",
        "  df_to = df['claimReviewed'].to_list()\n",
        "  # Encodes the dataset\n",
        "  corpus_embeddings = embedder.encode(df_to)\n",
        "  # Reads the embeddings of the dataset's claimReviewed column previously encoded\n",
        "  obj = pd.read_pickle(r'/content/gdrive/MyDrive/Datasets/sts-embeddings.pkl')\n",
        "  top5 = []\n",
        "\n",
        "  for query in queries:\n",
        "    query_embedding = embedder.encode(query)\n",
        "    intro = f\"Query: {query}\"\n",
        "    title = f\"\\nTop 5 of Similar Claims: \"\n",
        "\n",
        "    # Perform semantic search and retrieve the top 5 hits\n",
        "    hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=5)\n",
        "    hits = hits[0]\n",
        "\n",
        "    # Iterate through the hits and print information about the similar claims\n",
        "    for hit in hits:\n",
        "      for i in range(len(df)):\n",
        "        if df_to[hit['corpus_id']] == df['claimReviewed'][i]:\n",
        "          top_iter = f\"Claim Verified: {df_to[hit['corpus_id']]}, \\n(Score: {(hit['score']):.4f})\\n Published Date: {df['datePublished'][i]}\\n Link: {df['link'][i]}\\n Assessment: {df['label'][i]}\\n\"\n",
        "          top5.append(top_iter)\n",
        "  return f\"{intro}\\n{title}{{'\\n'.join(top5)}}\""
      ],
      "metadata": {
        "id": "dh3u-DvODHyk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_top5(prediction_corpus)"
      ],
      "metadata": {
        "id": "kAUO-o3jDZ5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "bc0d5ff9-caf1-4fa3-a5fd-f100e014d2ae"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Query: O câncer começa quando as alterações genéticas interferem na replicação normal e na reposição das células do corpo. As células começam a crescer descontroladamente e podem formar um tumor. É a segunda principal causa de morte nos Estados Unidos. Infelizmente, parece que a doença pode estar aumentando graças às injeções experimentais de Covid-19. Porque os dados oficiais do governo dos EUA confirmam que o risco de desenvolver câncer após a vacinação contra o Covid-19 aumenta em chocantes 143.233%\\n\\nTop 5 of Similar Claims: {'\\n'.join(top5)}\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FINAL FUNCTION DEMONSTRATION ON SAMPLE QUERY"
      ],
      "metadata": {
        "id": "48lVPzAFr-hV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the sample query as the user would provide\n",
        "sample_query = ['Um novo estudo prospectivo que inclui mais de 223.000 participantes do sul do Brasil descobriu que a ivermectina reduz a mortalidade por covid-19 em 92% . O uso de ivermectina foi associado a reduções não apenas na mortalidade por COVID-19, mas também nas hospitalizações e nas taxas de infecção. Como profilático, a ivermectina mostrou-se mais eficaz de maneira dose-dependente. À medida que a dose de ivermectina aumentava, os pacientes tinham maior probabilidade de se recuperar da covid-19. Evidências preliminares também mostram que os pacientes se recuperam mais rapidamente com ivermectina .']"
      ],
      "metadata": {
        "id": "y4MML1G9jIkW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7LJQfx1m6MKJ"
      },
      "outputs": [],
      "source": [
        "# Final function calls the function loaded_model_Predict once for the first feature of the application\n",
        "# (Is the input data a case of disinformation or not?) and then for the second feature (What are the Covid-related themes?),\n",
        "# transforming the positive output into a list of indexes, to be translated to the themes in the front end.\n",
        "# Next, it runs the function generate_top_5. The final output is transformed into a JSON string,\n",
        "# which is the method of transfer from the backend to the front end.\n",
        "# As all tokenizers and models are saved into the application server, the load time is definitely viable for a web application.\n",
        "# As such, this function was run again after the loading of the tokenizer and the model to exemply a normal run.\n",
        "\n",
        "def getOutputAsJson():\n",
        "  start = time.time()\n",
        "\n",
        "  feature_fake_or_not = loaded_model_predict(\"BERTPT\", dataset = sample_query)\n",
        "\n",
        "  feature_theme_output = loaded_model_predict(\"DEBERTA_ML\", dataset = sample_query, multilabel=True)\n",
        "  positives_outcomes = np.where(feature_theme_output == 1)\n",
        "  feature_theme = positives_outcomes[1].tolist()\n",
        "\n",
        "  feature_top5_similar_results = generate_top5(sample_query)\n",
        "  end = time.time()\n",
        "  total_time = end - start\n",
        "  data = {\n",
        "    'Probability' : str(feature_fake_or_not),\n",
        "\n",
        "    'Covid Themes' : str(feature_theme),\n",
        "\n",
        "    'Similar Claims TOP 5' : feature_top5_similar_results\n",
        "  }\n",
        "  print(f\"Total Time: {total_time}\")\n",
        "  json_string = json.dumps(data,ensure_ascii=False)\n",
        "  return json_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "nLFlKZac7qgh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "4a33cd93-428d-42dd-bc2e-34c6cb43a1bd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\n",
            "Prediction Time: 1.5511224269866943\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0. 1. 0. 0. 0.]]\n",
            "Prediction Time: 4.542011022567749\n",
            "Total Time: 14.4563148021698\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"Probability\": \"[1]\", \"Covid Themes\": \"[4]\", \"Similar Claims TOP 5\": \"Query: Um novo estudo prospectivo que inclui mais de 223.000 participantes do sul do Brasil descobriu que a ivermectina reduz a mortalidade por covid-19 em 92% . O uso de ivermectina foi associado a reduções não apenas na mortalidade por COVID-19, mas também nas hospitalizações e nas taxas de infecção. Como profilático, a ivermectina mostrou-se mais eficaz de maneira dose-dependente. À medida que a dose de ivermectina aumentava, os pacientes tinham maior probabilidade de se recuperar da covid-19. Evidências preliminares também mostram que os pacientes se recuperam mais rapidamente com ivermectina .\\\\n\\\\nTop 5 of Similar Claims: {\\'\\\\n\\'.join(top5)}\"}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "json_string = getOutputAsJson()\n",
        "json_string"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is a way to save the JSON string to upload to GitHub as an example\n",
        "def saveJsonFile(json_string):\n",
        "  with open('json_data.json', 'w', encoding='utf-8') as outfile:\n",
        "    outfile.write(json_string)"
      ],
      "metadata": {
        "id": "MCHh3N8ytVOl"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saveJsonFile(json_string)"
      ],
      "metadata": {
        "id": "6raej6mmtV6G"
      },
      "execution_count": 22,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}